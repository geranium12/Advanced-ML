{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Продвинутое машинное обучение: ДЗ 3\n",
    "### Герасимчик Анна. ML-22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Третье домашнее задание посвящено достаточно простой, но, надеюсь, интересной задаче, в которой потребуется творчески применить методы сэмплирования. Как и раньше, в качестве решения ожидается ссылка на jupyter-ноутбук на вашем github (или публичный, или с доступом для snikolenko); ссылку обязательно нужно прислать в виде сданного домашнего задания на портале Академии. Как всегда, любые комментарии, новые идеи и рассуждения на тему категорически приветствуются. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом небольшом домашнем задании мы попробуем улучшить метод Шерлока Холмса. Как известно, в рассказе The Adventure of the Dancing Men великий сыщик расшифровал загадочные письмена. Пользовался он для этого так называемым частотным методом: смотрел, какие буквы чаще встречаются в зашифрованных текстах, и пытался подставить буквы в соответствии с частотной таблицей: E — самая частая и так далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы будем разрабатывать более современный и продвинутый вариант такого частотного метода. В качестве корпусов текстов для подсчётов частот можете взять что угодно, но для удобства вот вам $\\href{https://www.dropbox.com/s/k23enjvr3fb40o5/corpora.zip}{“Война~и~мир”}$ по-русски и по-английски:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'corpora/'\n",
    "RUSSIAN_ALPHABET = ' абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "SAMPLE_LENGTH = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        data = f.read().replace('\\n', ' ')\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anna_karenina = read_data(DATA_PATH + 'AnnaKarenina.txt')\n",
    "war_and_peace = read_data(DATA_PATH + 'WarAndPeace.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "- подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "- возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "- расшифруйте их таким частотным методом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str, alphabet: str) -> str:\n",
    "    cleaned = ''\n",
    "    for c in text.lower():\n",
    "        if c in alphabet:\n",
    "            cleaned += c\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def accuracy(original: str, decoded: str) -> float:\n",
    "    correct = 0\n",
    "    for i in range(len(original)):\n",
    "        if original[i] == decoded[i]:\n",
    "            correct += 1\n",
    "    return correct / len(original)\n",
    "\n",
    "\n",
    "def get_freq_dict(text: str, step: int = 1) -> Dict:\n",
    "    freq_dict = Counter()\n",
    "    for i in range(0, len(text) - 1):\n",
    "        freq_dict[text[i:i + step]] += 1\n",
    "    freq_dict_sorted = sorted(dict(freq_dict).items(), key=lambda item: item[1], reverse=True)\n",
    "    freq_dict_balanced = {}\n",
    "    for k, v in freq_dict_sorted:\n",
    "        freq_dict_balanced[k] = v / len(text)\n",
    "    return freq_dict_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text: str, step: int = 1) -> str:\n",
    "    encode_dict = get_encode_dict(text, step)\n",
    "    encoded = ''\n",
    "    for i in range(len(text) - step + 1):\n",
    "        encoded += encode_dict[text[i:i + step]]\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def get_encode_dict(text: str, step:int = 1) -> Dict:\n",
    "    freq_dict = get_freq_dict(text, step)\n",
    "    keys = list(freq_dict.keys())\n",
    "    shuffled_keys = keys.copy()\n",
    "    random.shuffle(shuffled_keys)\n",
    "    encode_dict = {}\n",
    "    for i in range(len(shuffled_keys)):\n",
    "        encode_dict[keys[i]] = shuffled_keys[i]\n",
    "    return encode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(text: str, freq_dict: Dict, step: int = 1) -> Dict:\n",
    "    decode_dict = get_decode_dict(text, freq_dict, step)\n",
    "    decoded = ''\n",
    "    for i in range(len(text) - step + 1):\n",
    "        if text[i:i + step] in decode_dict.keys():\n",
    "            decoded += decode_dict[text[i:i + step]]\n",
    "        else:\n",
    "            decoded += str('*' * step)\n",
    "    return decoded\n",
    "\n",
    "\n",
    "def get_decode_dict(text: str, freq_list: List, step: int = 1) -> Dict:\n",
    "    freq_dict = get_freq_dict(text, step)\n",
    "    keys = list(freq_dict.keys())\n",
    "    decode_dict = {}\n",
    "    for i in range(min(len(freq_dict),len(freq_list))):\n",
    "        decode_dict[keys[i]] = freq_list[i]\n",
    "    return decode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding(train: str, freq_dict: Dict, step: int = 1) -> str:\n",
    "    encoded = encode(train, step)\n",
    "    decoded = decode(encoded, list(freq_dict.keys()), step)\n",
    "    decoding_accuracy = accuracy(train, decoded)\n",
    "    print(f'sample: {train[:SAMPLE_LENGTH]}\\n')\n",
    "    print(f'encoded: {encoded[:SAMPLE_LENGTH]}\\n')\n",
    "    print(f'decoded: {decoded[:SAMPLE_LENGTH]}\\n')\n",
    "    print(f'accuracy: {round(decoding_accuracy * 100, 3)}%')\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "anna_karenina = clean_text(anna_karenina, RUSSIAN_ALPHABET)\n",
    "war_and_peace = clean_text(war_and_peace, RUSSIAN_ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anna_karenina_dict = get_freq_dict(anna_karenina)\n",
    "war_and_peace_dict = get_freq_dict(war_and_peace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anna_karenina_dict: {' ': 0.17910812333922474, 'о': 0.0944538757383889, 'е': 0.0719124047007973, 'а': 0.06810538002492653, 'н': 0.05707570954251148, 'и': 0.05459526954211601, 'т': 0.049224375426371064, 'с': 0.04369063882525431, 'л': 0.041242185741628294, 'в': 0.03871114825470658, 'р': 0.03273657378247617, 'к': 0.028183381575419626, 'д': 0.024212351253567268, 'м': 0.023569705016653553, 'у': 0.022175075445505052, 'п': 0.019827817334931518, 'я': 0.017705630802354006, 'ь': 0.016198756232359942, 'ы': 0.015245546112630005, 'г': 0.014942542773777474, 'б': 0.014375501976500666, 'ч': 0.013875342914287277, 'з': 0.013446718229576498, 'ж': 0.009316916484486636, 'й': 0.008643446491413258, 'ш': 0.007018511119524639, 'х': 0.006389241229623607, 'ю': 0.00512488564677255, 'э': 0.0029189515502895396, 'щ': 0.002357726556061724, 'ц': 0.0023222501574628675, 'ф': 0.0010357945230256367, 'ъ': 0.00023961108561850773, 'ё': 1.802898945187801e-05}\n",
      "war_and_peace_dict: {' ': 0.17873405534032794, 'о': 0.09335919111654131, 'а': 0.06887300791729573, 'е': 0.06477496568460918, 'и': 0.0545968912769591, 'н': 0.053501540955285636, 'т': 0.046646079971237535, 'с': 0.04285120145762335, 'л': 0.04155475761375114, 'в': 0.037817769659557805, 'р': 0.037430816972902646, 'к': 0.029444966644373724, 'д': 0.02496454203235473, 'м': 0.024283566241272616, 'у': 0.023543176454995422, 'п': 0.021095015165803133, 'я': 0.019007908155104045, 'г': 0.017027441648601257, 'ь': 0.01599302875789711, 'ы': 0.01558931827772539, 'з': 0.014628030304184421, 'б': 0.01418318705810841, 'ч': 0.01119572950483767, 'й': 0.009460536157986383, 'ж': 0.0083179593273117, 'ш': 0.007754288090845522, 'х': 0.007007804561471395, 'ю': 0.005324408030944028, 'ц': 0.0033195665520535152, 'э': 0.0024816768762254138, 'щ': 0.0023064817621886286, 'ф': 0.0018418338510475907, 'ё': 0.0006566008186943851, 'ъ': 0.0004311323241079141}\n"
     ]
    }
   ],
   "source": [
    "print(f'anna_karenina_dict: {anna_karenina_dict}')\n",
    "print(f'war_and_peace_dict: {war_and_peace_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:    анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива посвоему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве            лев толстойроман широкого дыхания  часть первая   лев толстой  анна каренина     роман широкого дыхания     анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно сочетались в этом романе с цельностью художественного взгляда автора на жизнь он выступал з\n",
      "\n",
      "encoded:    оппо долбпыпо уяып ыю еожнэ юпожбпыцнэ лужопук мрко цумецуёу посыпобцев ецокщба оиулыюжуж илоюуа кеб есоецмыкнб ебжры ъуэузы яльё по яльёо дозяов пбесоецмыков ебжрв пбесоецмыко ъуекубжь йцу дпыёо у кбспнэ тбппуецвэ у мчгкы у кблб у ебжрб у сбмукбсбедуж яуецуыпецкб            мбк цумецуалужоп щылудуёу янэопыв  соецр ъблков   мбк цумецуа  оппо долбпыпо     лужоп щылудуёу янэопыв     оппо долбпыпо ъулоюымо еуклбжбппыдук кебяпбкпуецрч еуяблзопыв пбугнсоапов екугуяо лоедукоппуецр ъукбецкукопыв ьяыкыцбмрпу еусбцомыер к йцуж лужопб е тбмрпуецрч эьяузбецкбппуёу кюёмвяо окцуло по зыюпр уп кнецьъом ю\n",
      "\n",
      "decoded:    анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива посвоему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве            лев толстойроман широкого дыхания  часть первая   лев толстой  анна каренина     роман широкого дыхания     анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно сочетались в этом романе с цельностью художественного взгляда автора на жизнь он выступал з\n",
      "\n",
      "accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "decoded = decoding(anna_karenina, anna_karenina_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:    война и мир  самый известный роман льва николаевича толстого как никакое другое произведение писателя отражает глубину его мироощущения и философииэта книга из разряда вечных потому что она обо всем  о жизни и смерти о любви и чести о мужестве и героизме о славе и подвиге о войне и мирепервый том знакомит с высшим обществом россии  века показаны взаимоотношения между родителями и детьми в семье ростовых сватовство у болконских интриги у безуховых вечера в салоне фрейлины апшерер балы в москве и петербурге            лев николаевич толстойчасть первая  часть орая  часть третья              л\n",
      "\n",
      "encoded: ссслвымцсасеарссицефысаэлъигмфысрвецмсшблцсмаьвшцълащцсгвшигвувсьцьсмаьцьвъсхр увъстрваэлъхъмаъстаицгъшюсвгрцзцъгсуш йам съувсеарввк къмаюсасёашвивёаангцсьмауцсаэсрцэрюхцслъщмфжствгве сщгвсвмцсвйвслиъессвсзаэмасасиеъргасвсшчйласасщъигасвсе зъиглъсасуърваэеъсвсишцлъсаствхлауъсвслвымъсасеарътърлфысгвесэмцьвеагсислфидаесвйкъиглвесрвииаасслъьцствьцэцмфслэцаеввгмвдъмаюсеъзх срвхагъшюеасасхъгбеаслсиъебъсрвигвлфжсилцгвлиглвс сйвшьвмиьажсамграуас сйъэ жвлфжслъщърцслсицшвмъсёръышамфсцтдърърсйцшфслсевиьлъсастъгърй руъссссссссссссшълсмаьвшцълащсгвшигвыщцигбстърлцюссщцигбсврцюссщцигбсгръгбюссссссссссссссш\n",
      "\n",
      "decoded:    вожие н мнр  семгж нбвастигж ромеи лыве инколеавнзе толстоьо кек инкекоа друьоа пронбвадаина пнсеталя отрейеат ьлучниу аьо мнрооцуцаиня н фнлософннщте кинье нб ребряде вазигх потому зто оие очо всам  о йнбин н смартн о лючвн н застн о муйаства н ьаронбма о слева н подвньа о вожиа н мнрапарвгж том биекомнт с вгсшнм очцаством росснн  ваке покебеиг вбенмоотиошаиня майду роднталямн н датымн в самыа ростовгх световство у чолкоискнх нитрньн у чабуховгх вазаре в селоиа фражлниг епшарар челг в москва н патарчурьа            лав инколеавнз толстожзесты парвея  зесты орея  зесты тратыя              л\n",
      "\n",
      "accuracy: 64.266%\n"
     ]
    }
   ],
   "source": [
    "decoded = decoding(war_and_peace, anna_karenina_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "- подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "- проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:    война и мир  самый известный роман льва николаевича толстого как никакое другое произведение писателя отражает глубину его мироощущения и философииэта книга из разряда вечных потому что она обо всем  о жизни и смерти о любви и чести о мужестве и героизме о славе и подвиге о войне и мирепервый том знакомит с высшим обществом россии  века показаны взаимоотношения между родителями и детьми в семье ростовых сватовство у болконских интриги у безуховых вечера в салоне фрейлины апшерер балы в москве и петербурге            лев николаевич толстойчасть первая  часть орая  часть третья              л\n",
      "\n",
      "encoded: ититбьутгнятщььфхлзмеоцемакнитайюгзцьдяюцвхлтсыщящей пыеуаяюцвщеу ыбжднщвцэтипчкдшьфа дзксззымоцж ьнщркогльфчлббымез пббэмсбпфмнсржгжча дзкссржгззегэ ршбыожепсбегэ отф у еятсыщящ лч эгдзбхэ отщиётюгрлячефпизчлез  ядпяхнрж эрниавбчеаншлэпндфедппкхсбпфеоцемау иьаецкекелэгдзфизчхлзмйоскйбгтмюоэчьск вьюжжпцьфмниддзджвньфхлтсржщедпядынысинжеьфбьящмсгыуаюлбюотщэз ббыбагеднеыцббпфлепыщььфленыддпфбьтщтбищзъитлепфетрчтсб дззмхлзмайумбниэвснязмлепфэтсз ъбцщрзмхлзмнецаей пнязмлепфеоагйтхаей ппяящэ хлзмавя иэу еятсвпбнэ лепфайяноцдхящэ хлзмотщэтнзйщрджя э лепфбьутгнятрщэ хлзмеоцемадюиюзыиэвхякяюцвчлббыбзъ\n",
      "\n",
      "decoded:  у **т************жз**и**ьйе****************** **л**********************ь******************я********************************************у************иав**********д******************************и******к**********я**к******шчо**ы**ф**********в**********ф******д******с******************ш******с**н**********************************************с**нж****************************г**м**********щ**************************************************ющ********шчо************************ё************************г**ьйе**************************************************и**ы******************и**ь****ф******ющ****\n",
      "\n",
      "accuracy: 0.483%\n"
     ]
    }
   ],
   "source": [
    "decoded = decoding(war_and_peace, anna_karenina_dict, step=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "- предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "- реализуйте и протестируйте его, убедитесь, что результаты улучшились."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc(text, text_for_train, iters, alphabet):\n",
    "    \n",
    "    def get_log_likelihood(text, permutation):\n",
    "        text = text.translate(str.maketrans(alphabet, ''.join(permutation)))\n",
    "        likelihood = 0\n",
    "        for i in range(len(text) - 1):\n",
    "            likelihood += transitions_matrix[embeddings[text[i]], embeddings[text[i+1]]]\n",
    "        return likelihood\n",
    "\n",
    "\n",
    "    embeddings = {c: i for i, c in enumerate(RUSSIAN_ALPHABET)}\n",
    "    transitions_matrix = np.zeros((len(embeddings), len(embeddings)))\n",
    "    for i in range(len(text_for_train)-1):\n",
    "        x = embeddings[text_for_train[i]]\n",
    "        y = embeddings[text_for_train[i + 1]]\n",
    "        transitions_matrix[x, y] += 1\n",
    "    transitions_matrix = np.clip(transitions_matrix, 1, None)\n",
    "    transitions_matrix = (np.log(transitions_matrix).T - np.log(transitions_matrix.sum(axis=1))).T\n",
    "    \n",
    "    permutation = np.array(list(RUSSIAN_ALPHABET))\n",
    "    random.shuffle(permutation)\n",
    "    permutation_best = permutation.copy()\n",
    "    \n",
    "    log_likelihood = get_log_likelihood(text, permutation)\n",
    "    log_likelihood_best = log_likelihood\n",
    "    \n",
    "    for i in tqdm(range(iters)):\n",
    "        swapped = random.sample(range(len(RUSSIAN_ALPHABET)), 2)\n",
    "        permutation[swapped[0]], permutation[swapped[1]] = permutation[swapped[1]], permutation[swapped[0]]\n",
    "        \n",
    "        log_likelihood_current = get_log_likelihood(text, permutation)\n",
    "        if log_likelihood_current < log_likelihood:\n",
    "            delta = np.exp(log_likelihood_current - log_likelihood)\n",
    "            if delta < random.random():\n",
    "                permutation[swapped[0]], permutation[swapped[1]] = permutation[swapped[1]], permutation[swapped[0]]\n",
    "            else:\n",
    "                log_likelihood = log_likelihood_current\n",
    "        else:\n",
    "            log_likelihood = log_likelihood_current\n",
    "            if log_likelihood_current > log_likelihood_best:\n",
    "                permutation_best = permutation.copy()\n",
    "                log_likelihood_best = log_likelihood_current\n",
    "    return text.translate(str.maketrans(RUSSIAN_ALPHABET, ''.join(permutation_best)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [00:31<00:00, 3129.31it/s]\n"
     ]
    }
   ],
   "source": [
    "encoded = encode(anna_karenina)[:SAMPLE_LENGTH]\n",
    "decoded = mcmc(encoded, war_and_peace, 100000, RUSSIAN_ALPHABET)\n",
    "decoding_accuracy = accuracy(anna_karenina[:SAMPLE_LENGTH], decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: ооохммхотхлъмщмхордщмощыоюхйсзоымхйъмщесзолрйхмржоёфжхоерёюераромхящмхъеюгоюехжиъуохцрлщыйрйоцлхыруожюъоюяхюеёщжсъоюъйфщоврзршщодлнаомходлнахотхшдхгомъюяхюеёщжхгоюъйфгомъюяхюеёщжховрюжръйноперотмщахорожъямсзоэъммрюегзороёк жщорожълъороюъйфъорояъёржъяъютрйодрюерщмюежъооооооооооооёъжоерёюерулрйхмоищлртрародсзхмщгоояхюефовължхгоооёъжоерёюеруоохммхотхлъмщмхооооолрйхмоищлртрародсзхмщгооооохммхотхлъмщмховрлхыщёхоюржлъйъммщтржожюъдмъжмрюефкоюрдълшхмщгомър сяхумхгоюжр рдхолхютржхммрюефовржъюежржхмщгондщжщеъёфмроюряъехёщюфожоперйолрйхмъоюоэъёфмрюефкозндршъюежъммрарожыаёгдхохжерлхомхошщымформожсюенвхёоы\n",
      "\n",
      "decoded:    анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива посвоему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве            лев толстойроман широкого дыхания  часть первая   лев толстой  анна каренина     роман широкого дыхания     анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно сочетались в этом романе с цельностью художественного взгляда автора на жизнь он выступал з\n",
      "\n",
      "accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(f'encoded: {encoded[:SAMPLE_LENGTH]}\\n')\n",
    "print(f'decoded: {decoded[:SAMPLE_LENGTH]}\\n')\n",
    "print(f'accuracy: {round(decoding_accuracy * 100, 3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расшифруйте сообщение:\n",
    "\n",
    "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или это (они одинаковые, второй вариант просто на случай проблем с юникодом):\n",
    "\n",
    "დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ru_letters(freq_dict: Dict) -> List:\n",
    "    ru_letters = []\n",
    "    for i in list(freq_dict.keys()):\n",
    "        if i in RUSSIAN_ALPHABET:\n",
    "            ru_letters.append(i)\n",
    "    return ru_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1000000/1000000 [02:26<00:00, 6837.62it/s]\n"
     ]
    }
   ],
   "source": [
    "sample = 'დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ'\n",
    "sample = sample.translate(str.maketrans(''.join(set(sample)), ''.join(get_ru_letters(war_and_peace_dict)[:len(set(sample))])))\n",
    "decoded = mcmc(sample, war_and_peace + anna_karenina, 1000000, RUSSIAN_ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded: если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'decoded: {decoded}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
